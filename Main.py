from FRONTEND.GUI import (
    SiriStyleOverlay
)
from BACKEND.Model import FirstLayerDMM
from BACKEND.RealtimeSearchEngine import RealtimeSearchEngine
from BACKEND.Automation import Automation
from BACKEND.SpeechToText import SpeechRecognition
from BACKEND.TextToSpeech import TextToSpeech
from BACKEND.Chatbot import ChatBot
from BACKEND.FileAccess import list_all_files
from dotenv import dotenv_values, load_dotenv
from asyncio import run
from time import sleep
import subprocess
import threading
import json
import os
from PyQt5.QtWidgets import QApplication
from WAKEWORD.wake_word import detect_wake_word
from threading import Thread
import cohere
import pyttsx3
import speech_recognition as sr
import sys
from AURA.aura_controller import AURAController

aura = AURAController()
print("AURA loaded successfully")



# Load environment variables
env_vars = dotenv_values(".env")
Username = env_vars.get("Username")
Assistantname = env_vars.get("Assistantname")


load_dotenv()
api_key = os.getenv("CO_API_KEY")

if api_key is None:
    api_key = "EgH36K0KfAK0c9JIxsFsI4wW4455AVs5Ym0guW6Z"

co = cohere.Client(api_key)

DefaultMessage = f'''{Username} : Hello {Assistantname}, How are you?
{Assistantname} : Hello {Username}, I am doing well. How are you? And How may I help you?'''

process_list = []
Functions = ["open", "close", "play", "system", "content", "google search", "youtube search"]

MEMORY_FILE = "Data/relationship_memory.json"

def speak(text):
    engine = pyttsx3.init()
    engine.say(text)
    engine.runAndWait()

def listen():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print("Listening...")
        audio = r.listen(source)
    try:
        text = r.recognize_google(audio)
        return text
    except:
        speak("Sorry, I couldn't hear that.")
        return ""
    
def start_assistant():
    print("Waking up Darling...")
    # call your GUI or assistant trigger here


def resource_path(relative_path):
    """ Get absolute path to resource inside .app or script """
    try:
        base_path = sys._MEIPASS  # set by PyInstaller
    except Exception:
        base_path = os.path.abspath(".")

    return os.path.join(base_path, relative_path)


def load_memory():
    if not os.path.exists(MEMORY_FILE):
        return {"preferences": {}, "history": [], "nickname": "Darling", "mood": "happy"}
    with open(MEMORY_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

def save_memory(memory):
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(memory, f, indent=4)

def handle_file_access():
            files = list_all_files("/Users/girishkumarsamal")  # You can use '/' for full access
            print(f"Found {len(files)} files.")
            # You can perform file-related operations here
            print("ACCESSING THE FILES U WANT.")


def MainExecution():
    QueryFinal = None
    TaskExecution = False
    ImageExecution = False
    ImageGenerationQuery = ""
    Answer = ""
    Query = SpeechRecognition()

    # ---------- AURA DECISION ----------
    aura_result = aura.evaluate(Query)

    # If AURA says reject or stay silent, do nothing
    if aura_result.reject or not aura_result.respond:
        return True

    from FRONTEND.GUI import update_label
    update_label(f"{Query}")
    
    if "stop listening" in Query.lower():
        update_label("Stopped Listening")
        return False

    Decision = FirstLayerDMM(Query)
    memory = load_memory()

    print(f"\nDecision : {Decision}\n")

    G = any(i.startswith("general") for i in Decision)
    R = any(i.startswith("realtime") for i in Decision)

    Mearged_query = " and ".join(
        " ".join(i.split()[1:]) for i in Decision if i.startswith("general") or i.startswith("realtime")
    )

    for queries in Decision:
        if "generate " in queries:
            ImageGenerationQuery = queries
            ImageExecution = True

    for queries in Decision:
        if not TaskExecution:
            if any(queries.startswith(func) for func in Functions):
                run(Automation(Decision))
                TaskExecution = True

    if ImageExecution:
        try:
            p1 = subprocess.Popen(['python3', r'BACKEND/ImageGeneration.py'],
                                  stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                                  stdin=subprocess.PIPE, shell=False)
            process_list.append(p1)
        except Exception as e:
            print(f"Error starting ImageGeneration.py: {e}")

    if G and R or R:
        Answer = RealtimeSearchEngine(Mearged_query)
        TextToSpeech(Answer)
        return True
    else:
        for Queries in Decision:
            if "general" in Queries:
                QueryFinal = Queries.replace("general: ", "")
                Answer=ChatBot(QueryFinal)
                if aura_result.respond:
                    TextToSpeech(Answer, memory.get("mood", "neutral"))
                return True
            elif "realtime" in Queries:
                QueryFinal = Queries.replace("realtime ", "")
                Answer = RealtimeSearchEngine(QueryFinal)
                if aura_result.respond:
                    TextToSpeech(Answer, memory.get("mood", "neutral"))
                return True
            elif "exit" in Queries:
                Answer = "Okay, Bye!"
                if aura_result.respond:
                    TextToSpeech(Answer, memory.get("mood", "neutral"))
                os._exit(1)

                # Example: Update mood or preferences based on keywords
                if "i love you" in Query.lower():
                    memory["mood"] = "loved"
                elif "you are annoying" in Query.lower():
                    memory["mood"] = "sad"
                elif "you make me angry" in Query.lower():
                    memory["mood"] = "angry"
                elif "thank you" in Query.lower():
                    memory["mood"] = "happy"

                if "call me" in Query.lower():
                   try:
                       nickname = Query.lower().split("call me")[-1].strip().split()[0]
                       if nickname:
                         memory["nickname"] = nickname.capitalize()
                         Answer = f"Alright! I'll call you {nickname.capitalize()} from now on."
                   except:
                        Answer = "Sorry, I couldn't understand the nickname you want me to use."
                
    # ---------- AURA MEMORY ----------
    if aura_result.remember:
        memory["history"].append({
            "user": Username,
            "query": Query,
            "response": Answer
        })
        save_memory(memory)
    return True

def FirstThread():
    while True:
        should_continue = MainExecution()
        if not should_continue:
            break
        sleep(0.1)

def SecondThread():
    import sys
    app = QApplication(sys.argv)
    window = SiriStyleOverlay()
    window.show()
    sys.exit(app.exec_())

# Correct main entry point
if __name__ == "__main__":
    print("[HEY DARLING] Starting wake word listener in background...")
    threading.Thread(target=FirstThread, daemon=True).start()
    SecondThread()
